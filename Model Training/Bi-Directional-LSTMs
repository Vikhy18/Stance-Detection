{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "H4-6sGu9Tsqm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pickle\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zflUWRqqT0Za",
        "outputId": "4004728b-5bfe-4025-c88f-4d9266e3836f"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "# drive.mount('/content/drive')\n",
        "df =pd.read_csv(\"../Datasets/restructured_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "x-RqQcdyT0f7"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into input and output\n",
        "X = df['Data']\n",
        "#X.append(data['reformulated_tweets'])\n",
        "Y=df['Stance']\n",
        "#Y.append(data['stance'])\n",
        "Y = pd.get_dummies(Y).values\n",
        "#targets = df['target'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "-3UtEw2gT0j5"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# Pad the sequences\n",
        "maxlen = 100\n",
        "X = pad_sequences(X, padding='post', maxlen=maxlen)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKpC3b_vT0mq",
        "outputId": "5701cff1-338e-4be4-87c4-c61367c695ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 128)         1280000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, None, 128)        98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,478,019\n",
            "Trainable params: 1,478,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = layers.Embedding(10000, 128)(inputs)\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1tbzO-r9n5OB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-7jM9qRaT0r-"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(learning_rate=0.003)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_m, precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nlXXoe50T_4f"
      },
      "outputs": [],
      "source": [
        "# # Define the model\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(10000, 128, input_length=maxlen))\n",
        "# model.add(Bidirectional(LSTM(64)))\n",
        "# model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4t1tKuzqDGZ",
        "outputId": "2d805872-fc88-4671-f607-2ba8c669b57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "36/36 [==============================] - 21s 443ms/step - loss: 0.9817 - accuracy: 0.5384 - f1_m: 0.4008 - precision_m: 0.5632 - recall_m: 0.3442 - val_loss: 0.9026 - val_accuracy: 0.5382 - val_f1_m: 0.4472 - val_precision_m: 0.6144 - val_recall_m: 0.3544\n",
            "Epoch 2/25\n",
            "36/36 [==============================] - 16s 448ms/step - loss: 0.6455 - accuracy: 0.6944 - f1_m: 0.6790 - precision_m: 0.7668 - recall_m: 0.6126 - val_loss: 1.1082 - val_accuracy: 0.5417 - val_f1_m: 0.5280 - val_precision_m: 0.5534 - val_recall_m: 0.5050\n",
            "Epoch 3/25\n",
            "36/36 [==============================] - 16s 447ms/step - loss: 0.4659 - accuracy: 0.7743 - f1_m: 0.7689 - precision_m: 0.7935 - recall_m: 0.7481 - val_loss: 1.1774 - val_accuracy: 0.5595 - val_f1_m: 0.5498 - val_precision_m: 0.5701 - val_recall_m: 0.5310\n",
            "Epoch 4/25\n",
            "36/36 [==============================] - 16s 447ms/step - loss: 0.2981 - accuracy: 0.8636 - f1_m: 0.8674 - precision_m: 0.8770 - recall_m: 0.8585 - val_loss: 1.3435 - val_accuracy: 0.5719 - val_f1_m: 0.5747 - val_precision_m: 0.5868 - val_recall_m: 0.5632\n",
            "Epoch 5/25\n",
            "36/36 [==============================] - 16s 445ms/step - loss: 0.1968 - accuracy: 0.9005 - f1_m: 0.9026 - precision_m: 0.9167 - recall_m: 0.8903 - val_loss: 1.6661 - val_accuracy: 0.5506 - val_f1_m: 0.5489 - val_precision_m: 0.5548 - val_recall_m: 0.5432\n",
            "Epoch 6/25\n",
            "36/36 [==============================] - 17s 473ms/step - loss: 0.1692 - accuracy: 0.9151 - f1_m: 0.9121 - precision_m: 0.9209 - recall_m: 0.9047 - val_loss: 1.7125 - val_accuracy: 0.5329 - val_f1_m: 0.5315 - val_precision_m: 0.5377 - val_recall_m: 0.5254\n",
            "Epoch 7/25\n",
            "36/36 [==============================] - 17s 483ms/step - loss: 0.1461 - accuracy: 0.9200 - f1_m: 0.9213 - precision_m: 0.9342 - recall_m: 0.9102 - val_loss: 1.8200 - val_accuracy: 0.5684 - val_f1_m: 0.5659 - val_precision_m: 0.5697 - val_recall_m: 0.5623\n",
            "Epoch 8/25\n",
            "36/36 [==============================] - 17s 471ms/step - loss: 0.1438 - accuracy: 0.9263 - f1_m: 0.9266 - precision_m: 0.9418 - recall_m: 0.9138 - val_loss: 1.9534 - val_accuracy: 0.5790 - val_f1_m: 0.5188 - val_precision_m: 0.5697 - val_recall_m: 0.4768\n",
            "Epoch 9/25\n",
            "36/36 [==============================] - 17s 461ms/step - loss: 0.1430 - accuracy: 0.9231 - f1_m: 0.9216 - precision_m: 0.9303 - recall_m: 0.9141 - val_loss: 1.9888 - val_accuracy: 0.5702 - val_f1_m: 0.5728 - val_precision_m: 0.5747 - val_recall_m: 0.5710\n",
            "Epoch 10/25\n",
            "36/36 [==============================] - 16s 458ms/step - loss: 0.1477 - accuracy: 0.9254 - f1_m: 0.9236 - precision_m: 0.9408 - recall_m: 0.9090 - val_loss: 1.9860 - val_accuracy: 0.5684 - val_f1_m: 0.5061 - val_precision_m: 0.5560 - val_recall_m: 0.4650\n",
            "Epoch 11/25\n",
            "36/36 [==============================] - 17s 471ms/step - loss: 0.1393 - accuracy: 0.9240 - f1_m: 0.9194 - precision_m: 0.9456 - recall_m: 0.8973 - val_loss: 2.0589 - val_accuracy: 0.5790 - val_f1_m: 0.5780 - val_precision_m: 0.5808 - val_recall_m: 0.5753\n",
            "Epoch 12/25\n",
            "36/36 [==============================] - 17s 460ms/step - loss: 0.1700 - accuracy: 0.9120 - f1_m: 0.9070 - precision_m: 0.9314 - recall_m: 0.8861 - val_loss: 1.7778 - val_accuracy: 0.5506 - val_f1_m: 0.5491 - val_precision_m: 0.5533 - val_recall_m: 0.5450\n",
            "Epoch 13/25\n",
            "36/36 [==============================] - 17s 462ms/step - loss: 0.1479 - accuracy: 0.9236 - f1_m: 0.9169 - precision_m: 0.9343 - recall_m: 0.9017 - val_loss: 1.9508 - val_accuracy: 0.5560 - val_f1_m: 0.4908 - val_precision_m: 0.5460 - val_recall_m: 0.4464\n",
            "Epoch 14/25\n",
            "36/36 [==============================] - 17s 467ms/step - loss: 0.1355 - accuracy: 0.9231 - f1_m: 0.9224 - precision_m: 0.9433 - recall_m: 0.9049 - val_loss: 1.9191 - val_accuracy: 0.5115 - val_f1_m: 0.5151 - val_precision_m: 0.5164 - val_recall_m: 0.5138\n",
            "Epoch 15/25\n",
            "36/36 [==============================] - 17s 474ms/step - loss: 0.1215 - accuracy: 0.9258 - f1_m: 0.9283 - precision_m: 0.9570 - recall_m: 0.9037 - val_loss: 2.1921 - val_accuracy: 0.5364 - val_f1_m: 0.5220 - val_precision_m: 0.5726 - val_recall_m: 0.4803\n",
            "Epoch 16/25\n",
            "36/36 [==============================] - 16s 457ms/step - loss: 0.1189 - accuracy: 0.9276 - f1_m: 0.9286 - precision_m: 0.9400 - recall_m: 0.9188 - val_loss: 2.2952 - val_accuracy: 0.5773 - val_f1_m: 0.5768 - val_precision_m: 0.5783 - val_recall_m: 0.5753\n",
            "Epoch 17/25\n",
            "36/36 [==============================] - 16s 450ms/step - loss: 0.1229 - accuracy: 0.9271 - f1_m: 0.9242 - precision_m: 0.9319 - recall_m: 0.9173 - val_loss: 2.3749 - val_accuracy: 0.5808 - val_f1_m: 0.5813 - val_precision_m: 0.5829 - val_recall_m: 0.5797\n",
            "Epoch 18/25\n",
            "36/36 [==============================] - 16s 450ms/step - loss: 0.1171 - accuracy: 0.9343 - f1_m: 0.9322 - precision_m: 0.9561 - recall_m: 0.9119 - val_loss: 2.3657 - val_accuracy: 0.5382 - val_f1_m: 0.5260 - val_precision_m: 0.5765 - val_recall_m: 0.4842\n",
            "Epoch 19/25\n",
            "36/36 [==============================] - 16s 457ms/step - loss: 0.1175 - accuracy: 0.9267 - f1_m: 0.9221 - precision_m: 0.9617 - recall_m: 0.8887 - val_loss: 2.4126 - val_accuracy: 0.5826 - val_f1_m: 0.5248 - val_precision_m: 0.5757 - val_recall_m: 0.4829\n",
            "Epoch 20/25\n",
            "36/36 [==============================] - 17s 467ms/step - loss: 0.1168 - accuracy: 0.9325 - f1_m: 0.9274 - precision_m: 0.9514 - recall_m: 0.9068 - val_loss: 2.4243 - val_accuracy: 0.5773 - val_f1_m: 0.5781 - val_precision_m: 0.5787 - val_recall_m: 0.5775\n",
            "Epoch 21/25\n",
            "36/36 [==============================] - 17s 472ms/step - loss: 0.1171 - accuracy: 0.9285 - f1_m: 0.9272 - precision_m: 0.9774 - recall_m: 0.8850 - val_loss: 2.4668 - val_accuracy: 0.5790 - val_f1_m: 0.5202 - val_precision_m: 0.5700 - val_recall_m: 0.4790\n",
            "Epoch 22/25\n",
            "36/36 [==============================] - 17s 477ms/step - loss: 0.1161 - accuracy: 0.9298 - f1_m: 0.9326 - precision_m: 0.9466 - recall_m: 0.9206 - val_loss: 2.5126 - val_accuracy: 0.5329 - val_f1_m: 0.5358 - val_precision_m: 0.5380 - val_recall_m: 0.5337\n",
            "Epoch 23/25\n",
            "36/36 [==============================] - 9s 251ms/step - loss: 0.1173 - accuracy: 0.9289 - f1_m: 0.9246 - precision_m: 0.9445 - recall_m: 0.9081 - val_loss: 2.5439 - val_accuracy: 0.5826 - val_f1_m: 0.5825 - val_precision_m: 0.5841 - val_recall_m: 0.5810\n",
            "Epoch 24/25\n",
            "36/36 [==============================] - 10s 267ms/step - loss: 0.1158 - accuracy: 0.9329 - f1_m: 0.9247 - precision_m: 0.9581 - recall_m: 0.8969 - val_loss: 2.6103 - val_accuracy: 0.5808 - val_f1_m: 0.5818 - val_precision_m: 0.5843 - val_recall_m: 0.5792\n",
            "Epoch 25/25\n",
            "36/36 [==============================] - 13s 363ms/step - loss: 0.1155 - accuracy: 0.9303 - f1_m: 0.9299 - precision_m: 0.9640 - recall_m: 0.9003 - val_loss: 2.6498 - val_accuracy: 0.5329 - val_f1_m: 0.5211 - val_precision_m: 0.5721 - val_recall_m: 0.4790\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2f71c766980>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, batch_size=64, epochs=25, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaH0WT2DiZu9",
        "outputId": "b8d04369-af19-4ba9-fbd4-7cd3c92c49a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 2.649840831756592\n",
            "Test accuracy: 0.5328596830368042\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.649840831756592,\n",
              " 0.5328596830368042,\n",
              " 0.521612286567688,\n",
              " 0.5730702877044678,\n",
              " 0.48008039593696594]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EC_BDXvUF0g",
        "outputId": "9c656471-c5ff-4f2f-b348-13ee1f861608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AGAINST: [1 0 0]\n",
            "FAVOR [1 0 0]\n",
            "NONE [1 0 0]\n"
          ]
        }
      ],
      "source": [
        "print(\"AGAINST:\",Y[0])\n",
        "print(\"FAVOR\",Y[10])\n",
        "print(\"NONE\",Y[9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrOi6JM1iZFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIBkm6LbUGH2",
        "outputId": "7f970b49-af66-4d25-dd4c-8f4a645ebde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "2\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Predict the stance of new texts\n",
        "new_texts = [\"Women are smart\", \"Feminism is a myth\"]\n",
        "new_targets = [\"Feminist Movement\",\"Feminist Movement\",\"Feminist Movement\"]\n",
        "new_texts = tokenizer.texts_to_sequences(new_texts)\n",
        "new_texts = pad_sequences(new_texts, padding='post', maxlen=maxlen)\n",
        "predictions = []\n",
        "for i in range(len(new_texts)):\n",
        "  pred = model.predict(np.array([new_texts[i]]))\n",
        "  print(np.argmax(pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "UjpduygmnMFM",
        "outputId": "41a22e4b-a9fe-417a-f281-365e17c4a534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 102ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.66      0.67       267\n",
            "           1       0.37      0.31      0.34       160\n",
            "           2       0.43      0.54      0.48       136\n",
            "\n",
            "    accuracy                           0.53       563\n",
            "   macro avg       0.50      0.51      0.50       563\n",
            "weighted avg       0.54      0.53      0.53       563\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
        "y_pred_bool = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(Y_test, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[176  60  31]\n",
            " [ 41  50  69]\n",
            " [ 38  24  74]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(confusion_matrix(y_true=y_test, y_pred=y_pred_bool))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5328596802841918\n",
            "Recall Score:  0.5328596802841918\n",
            "Precision Score:  0.5360975593930019\n",
            "F1 Score:  0.5317882379698788\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred_bool))\n",
        "print(\"Recall Score: \",recall_score(y_test, y_pred_bool, average='weighted'))\n",
        "print(\"Precision Score: \",precision_score(y_test, y_pred_bool, average='weighted'))\n",
        "print(\"F1 Score: \",f1_score(y_test, y_pred_bool, average='weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCE2Ff4gUM9B"
      },
      "outputs": [],
      "source": [
        "pickle.dump(model, open(\"Bi-LSTM.pkl\", 'wb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
